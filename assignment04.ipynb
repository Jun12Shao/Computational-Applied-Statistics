{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "- Donwload  ziptrain.csv and ziptest.csv datasets from  https://github.com/vahidpartovinia/ycbs255/\n",
    "\n",
    "# Digit learning challenge\n",
    "- Use the methods taught in the course, or a good combination of the methods taught in the course to predict all 10 digits of the zipcode data. Only use ziptrain.csv data to build your model, and evaluate the accuracy of your model on ziptest.csv \n",
    "\n",
    "- Your codes must be reproducible. We may run your codes on ziptrain.csv data on our own machine. \n",
    "\n",
    "# Submission note\n",
    "Please fill this jupyter notebook. Extract the pdf file as follows. On  Jupyter manue go to File/Print Preview, then on Browser menu go to File/Print. \n",
    "\n",
    "## Only PDF  Submissions will be graded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "# load training and test data\n",
    "path='data/'\n",
    "filename1=path+'ziptrain.csv'\n",
    "zipdata=np.loadtxt(filename1)\n",
    "\n",
    "filename2=path+'ziptest.csv'\n",
    "ziptest=np.loadtxt(filename2)\n",
    "\n",
    "X_train=zipdata[:,1:]\n",
    "y_train=zipdata[:,0]\n",
    "X_test=ziptest[:,1:]\n",
    "y_test=ziptest[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96750473199816089"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100,random_state=1)\n",
    "cross_val_score(rf,X_train,y_train,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94020926756352763"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97299441552267363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm=SVC(random_state=21)\n",
    "cross_val_score(svm,X_train,y_train,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9422022919780767"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97175027193232122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpc=MLPClassifier(random_state=4)\n",
    "cross_val_score(mlpc,X_train,y_train,cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94120577977080222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc.fit(X_train,y_train)\n",
    "y_pred=mlpc.predict(X_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Krange=np.arange(2,15)\n",
    "scores=np.zeros(13)\n",
    "for k in Krange:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores[k-2]=cross_val_score(knn,X_train,y_train,cv=5).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(2,15),scores,'r-')\n",
    "plt.title('KNeighborsClassifier' )\n",
    "plt.xlabel('K numbers')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k=3, kNN has the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94469357249626307"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As shown above, the KNeighborsClassifier(k=3) tops the list of these basic classifiers with a test accuracy of 0.94469, followed by SVM (0.9422)。 MLPC comes the third 0.9412, and Random Forest is the last 0.9402."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.5 Residual Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Network is a deep network based on Convoulutional Neural Network. The residual learning framework eases the training of \n",
    "these networks,and enables them to be substantially deeper — leading to improved performance in both visual and non-visual tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms as tfs\n",
    "\n",
    "#Hyper Parameters\n",
    "EPOCH=80\n",
    "BATCH_SIZE=100\n",
    "LR=0.001\n",
    "Modelname='ResNet.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construct ResNet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.res1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,3,stride,1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.downsample=downsample\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual=x\n",
    "        out=self.res1(x)\n",
    "        if self.downsample:\n",
    "            residual=self.downsample(x)\n",
    "        out+=residual\n",
    "        out=self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet Module\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,layers,num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(1,20,5,1,2),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.in_channels = 20\n",
    "        self.layer1=self.make_layer(block,20,blocks=layers[0])\n",
    "        self.layer2=self.make_layer(block,40,blocks=layers[1],stride=2)\n",
    "        self.layer3=self.make_layer(block,80,blocks=layers[2],stride=2)\n",
    "        self.avg_pool=nn.AvgPool2d(4)\n",
    "        self.fn=nn.Linear(80,num_classes)\n",
    "    def make_layer(self,block,out_channnels,blocks,stride=1):\n",
    "        downsample=None\n",
    "        if (stride != 1) or (self.in_channels != out_channnels):\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels,out_channnels,3,stride=stride,padding=1),\n",
    "                nn.BatchNorm2d(out_channnels)\n",
    "            )\n",
    "        layers=[]\n",
    "        layers.append(block(self.in_channels,out_channnels,stride=stride,downsample=downsample))\n",
    "        self.in_channels=out_channnels\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(out_channnels,out_channnels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.conv1(x)\n",
    "        out=self.layer1(out)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        out=self.avg_pool(out)\n",
    "        out=out.view(out.size(0),-1)\n",
    "        out=self.fn(out)\n",
    "        return out\n",
    "\n",
    "res_layers=[4,10,4]\n",
    "resnet=ResNet(ResidualBlock,res_layers).cuda()       #GPU\n",
    "optimizer=torch.optim.Adam(resnet.parameters(),lr=LR)   #optimize all cnn parameters\n",
    "loss_func=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data agumention\n",
    "transform = tfs.Compose([\n",
    "    tfs.ToPILImage(),\n",
    "    tfs.RandomRotation(180,expand=True),\n",
    "    tfs.RandomResizedCrop(16,scale=(0.8,1.2)),\n",
    "    tfs.RandomHorizontalFlip(),\n",
    "    tfs.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "path='data/'\n",
    "filename1=path+'ziptrain.csv'\n",
    "zipdata=np.loadtxt(filename1)\n",
    "\n",
    "filename2=path+'ziptest.csv'\n",
    "ziptest=np.loadtxt(filename2)\n",
    "\n",
    "np.random.shuffle(zipdata)\n",
    "train_data, valid_data= train_test_split(zipdata, test_size=0.1,random_state=4)\n",
    "valid_num = valid_data.shape[0]\n",
    "\n",
    "# transform training data from numpy to tensor, bundling\n",
    "train_x = train_data[:, 1:].reshape(-1, 16, 16)\n",
    "train_x = torch.from_numpy(train_x)  # transfo.type(torch.FloatTensor)rm to tensor from\n",
    "train_x = torch.unsqueeze(train_x, dim=1).type(torch.FloatTensor)\n",
    "train_num = train_x.shape[0]\n",
    "train_y = train_data[:, 0]\n",
    "train_y = torch.from_numpy(train_y).type(torch.LongTensor)\n",
    "dataset = Data.TensorDataset(train_x, train_y)\n",
    "\n",
    "# transform validation data from numpy to tensor\n",
    "valid_x = valid_data[:, 1:].reshape(-1, 16, 16)\n",
    "valid_x = torch.from_numpy(valid_x).type(torch.FloatTensor)  # transform to tensor from\n",
    "valid_x = Variable(torch.unsqueeze(valid_x, dim=1), volatile=True).cuda()\n",
    "\n",
    "valid_y = valid_data[:, 0]\n",
    "valid_y = torch.from_numpy(valid_y).type(torch.LongTensor).cuda()\n",
    "del train_data\n",
    "del valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjun1\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:159: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\sjun1\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:159: UserWarning: Couldn't retrieve source code for container of type ResidualBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Step: 0 |train loss: 2.3024420738220215 |valid accuracy: 0.19041095890410958\n",
      "Epoch: 0 Step: 20 |train loss: 0.5931494235992432 |valid accuracy: 0.8794520547945206\n",
      "Epoch: 0 Step: 40 |train loss: 0.2817847430706024 |valid accuracy: 0.9671232876712329\n",
      "Epoch: 0 Step: 60 |train loss: 0.15861625969409943 |valid accuracy: 0.9657534246575342\n",
      "Epoch: 1 Step: 0 |train loss: 0.1522427797317505 |valid accuracy: 0.963013698630137\n",
      "Epoch: 1 Step: 20 |train loss: 0.08110488206148148 |valid accuracy: 0.9698630136986301\n",
      "Epoch: 1 Step: 40 |train loss: 0.26341521739959717 |valid accuracy: 0.9780821917808219\n",
      "Epoch: 1 Step: 60 |train loss: 0.022509107366204262 |valid accuracy: 0.9767123287671233\n",
      "Epoch: 2 Step: 0 |train loss: 0.06494288891553879 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 2 Step: 20 |train loss: 0.018535947427153587 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 2 Step: 40 |train loss: 0.059712883085012436 |valid accuracy: 0.9726027397260274\n",
      "Epoch: 2 Step: 60 |train loss: 0.08098568022251129 |valid accuracy: 0.9739726027397261\n",
      "Epoch: 3 Step: 0 |train loss: 0.05178532004356384 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 3 Step: 20 |train loss: 0.06868288666009903 |valid accuracy: 0.9780821917808219\n",
      "Epoch: 3 Step: 40 |train loss: 0.022340603172779083 |valid accuracy: 0.989041095890411\n",
      "Epoch: 3 Step: 60 |train loss: 0.04305468499660492 |valid accuracy: 0.9794520547945206\n",
      "Epoch: 4 Step: 0 |train loss: 0.02999141626060009 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 4 Step: 20 |train loss: 0.0423741340637207 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 4 Step: 40 |train loss: 0.008000962436199188 |valid accuracy: 0.989041095890411\n",
      "Epoch: 4 Step: 60 |train loss: 0.027884967625141144 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 5 Step: 0 |train loss: 0.019188353791832924 |valid accuracy: 0.9767123287671233\n",
      "Epoch: 5 Step: 20 |train loss: 0.053611502051353455 |valid accuracy: 0.9808219178082191\n",
      "Epoch: 5 Step: 40 |train loss: 0.04455329850316048 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 5 Step: 60 |train loss: 0.034173741936683655 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 6 Step: 0 |train loss: 0.019854599609971046 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 6 Step: 20 |train loss: 0.024081818759441376 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 6 Step: 40 |train loss: 0.030431881546974182 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 6 Step: 60 |train loss: 0.01948910765349865 |valid accuracy: 0.9726027397260274\n",
      "Epoch: 7 Step: 0 |train loss: 0.06822514533996582 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 7 Step: 20 |train loss: 0.023090658709406853 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 7 Step: 40 |train loss: 0.01023870985955 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 7 Step: 60 |train loss: 0.022257084026932716 |valid accuracy: 0.989041095890411\n",
      "Epoch: 8 Step: 0 |train loss: 0.0027123140171170235 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 8 Step: 20 |train loss: 0.004308297764509916 |valid accuracy: 0.989041095890411\n",
      "Epoch: 8 Step: 40 |train loss: 0.011761932633817196 |valid accuracy: 0.9794520547945206\n",
      "Epoch: 8 Step: 60 |train loss: 0.0432300791144371 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 9 Step: 0 |train loss: 0.0066414810717105865 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 9 Step: 20 |train loss: 0.00306591740809381 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 9 Step: 40 |train loss: 0.015951354056596756 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 9 Step: 60 |train loss: 0.025893695652484894 |valid accuracy: 0.9808219178082191\n",
      "Epoch: 10 Step: 0 |train loss: 0.018111899495124817 |valid accuracy: 0.9821917808219178\n",
      "Epoch: 10 Step: 20 |train loss: 0.019616451114416122 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 10 Step: 40 |train loss: 0.00647640461102128 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 10 Step: 60 |train loss: 0.0035202025901526213 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 11 Step: 0 |train loss: 0.008547532372176647 |valid accuracy: 0.989041095890411\n",
      "Epoch: 11 Step: 20 |train loss: 0.004527850076556206 |valid accuracy: 0.989041095890411\n",
      "Epoch: 11 Step: 40 |train loss: 0.01001182571053505 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 11 Step: 60 |train loss: 0.020211393013596535 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 12 Step: 0 |train loss: 0.03522535040974617 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 12 Step: 20 |train loss: 0.01600523665547371 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 12 Step: 40 |train loss: 0.003977694548666477 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 12 Step: 60 |train loss: 0.017104236409068108 |valid accuracy: 0.9780821917808219\n",
      "Epoch: 13 Step: 0 |train loss: 0.0009326601284556091 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 13 Step: 20 |train loss: 0.007045569363981485 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 13 Step: 40 |train loss: 0.05671146512031555 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 13 Step: 60 |train loss: 0.03406009078025818 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 14 Step: 0 |train loss: 0.01950879767537117 |valid accuracy: 0.9808219178082191\n",
      "Epoch: 14 Step: 20 |train loss: 0.015408976934850216 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 14 Step: 40 |train loss: 0.0226439218968153 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 14 Step: 60 |train loss: 0.0022551727015525103 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 15 Step: 0 |train loss: 0.0058281635865569115 |valid accuracy: 0.989041095890411\n",
      "Epoch: 15 Step: 20 |train loss: 0.007542374078184366 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 15 Step: 40 |train loss: 0.006205713842064142 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 15 Step: 60 |train loss: 0.0011434268672019243 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 16 Step: 0 |train loss: 0.0014137744437903166 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 16 Step: 20 |train loss: 0.009105639532208443 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 16 Step: 40 |train loss: 0.0008443546248599887 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 16 Step: 60 |train loss: 0.0018645715899765491 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 17 Step: 0 |train loss: 0.0007070016581565142 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 17 Step: 20 |train loss: 0.0005290841800160706 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 17 Step: 40 |train loss: 0.00039695261511951685 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 17 Step: 60 |train loss: 0.0005237627192400396 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 18 Step: 0 |train loss: 0.0010599184315651655 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 18 Step: 20 |train loss: 0.0021653366275131702 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 18 Step: 40 |train loss: 0.0008343314984813333 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 18 Step: 60 |train loss: 0.00046045304043218493 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 19 Step: 0 |train loss: 0.00047855853335931897 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 19 Step: 20 |train loss: 0.0006164360092952847 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 19 Step: 40 |train loss: 0.0007867717649787664 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 19 Step: 60 |train loss: 0.0003612041473388672 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 20 Step: 0 |train loss: 0.0003804922162089497 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 20 Step: 20 |train loss: 0.0003170823911204934 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 20 Step: 40 |train loss: 0.0009343480924144387 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 20 Step: 60 |train loss: 0.000289998046355322 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 21 Step: 0 |train loss: 0.036787327378988266 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 21 Step: 20 |train loss: 0.0003308153245598078 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 21 Step: 40 |train loss: 0.0002252721751574427 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 21 Step: 60 |train loss: 0.0001821994810597971 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 22 Step: 0 |train loss: 0.00012087821960449219 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 22 Step: 20 |train loss: 0.0001903533993754536 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 22 Step: 40 |train loss: 0.00025392533279955387 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 22 Step: 60 |train loss: 0.0001389312674291432 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 23 Step: 0 |train loss: 0.0001256084506167099 |valid accuracy: 0.9958904109589041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 Step: 20 |train loss: 0.00010369301162427291 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 23 Step: 40 |train loss: 0.0001947545970324427 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 23 Step: 60 |train loss: 0.00014189719513524324 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 24 Step: 0 |train loss: 0.0002992725349031389 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 24 Step: 20 |train loss: 0.00029587268363684416 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 24 Step: 40 |train loss: 0.0007219553226605058 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 24 Step: 60 |train loss: 0.0001964616822078824 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 25 Step: 0 |train loss: 0.0003273439360782504 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 25 Step: 20 |train loss: 0.0003471803793217987 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 25 Step: 40 |train loss: 0.0011081122793257236 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 25 Step: 60 |train loss: 0.00024958132416941226 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 26 Step: 0 |train loss: 0.0002788495912682265 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 26 Step: 20 |train loss: 0.00010162830585613847 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 26 Step: 40 |train loss: 0.0001418399770045653 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 26 Step: 60 |train loss: 0.00014755726442672312 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 27 Step: 0 |train loss: 0.0001036977773765102 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 27 Step: 20 |train loss: 0.000420637137722224 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 27 Step: 40 |train loss: 0.0005117893451824784 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 27 Step: 60 |train loss: 0.00015937328862491995 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 28 Step: 0 |train loss: 0.048901062458753586 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 28 Step: 20 |train loss: 0.012582826428115368 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 28 Step: 40 |train loss: 0.02387130819261074 |valid accuracy: 0.9780821917808219\n",
      "Epoch: 28 Step: 60 |train loss: 0.008410424925386906 |valid accuracy: 0.9657534246575342\n",
      "Epoch: 29 Step: 0 |train loss: 0.04192645847797394 |valid accuracy: 0.9794520547945206\n",
      "Epoch: 29 Step: 20 |train loss: 0.023770036175847054 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 29 Step: 40 |train loss: 0.06122608110308647 |valid accuracy: 0.9767123287671233\n",
      "Epoch: 29 Step: 60 |train loss: 0.010004344396293163 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 30 Step: 0 |train loss: 0.0048993779346346855 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 30 Step: 20 |train loss: 0.0011460351524874568 |valid accuracy: 0.989041095890411\n",
      "Epoch: 30 Step: 40 |train loss: 0.0034013031981885433 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 30 Step: 60 |train loss: 0.008113260380923748 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 31 Step: 0 |train loss: 0.0010149049339815974 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 31 Step: 20 |train loss: 0.0007769537041895092 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 31 Step: 40 |train loss: 0.010729813948273659 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 31 Step: 60 |train loss: 0.0006807279423810542 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 32 Step: 0 |train loss: 0.00852096825838089 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 32 Step: 20 |train loss: 0.007644522003829479 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 32 Step: 40 |train loss: 0.02717563323676586 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 32 Step: 60 |train loss: 0.01919042505323887 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 33 Step: 0 |train loss: 0.0004756450653076172 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 33 Step: 20 |train loss: 0.0055320835672318935 |valid accuracy: 0.989041095890411\n",
      "Epoch: 33 Step: 40 |train loss: 0.0006396770477294922 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 33 Step: 60 |train loss: 0.005704615265130997 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 34 Step: 0 |train loss: 0.00045739649794995785 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 34 Step: 20 |train loss: 0.0008336401078850031 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 34 Step: 40 |train loss: 0.002227103803306818 |valid accuracy: 0.989041095890411\n",
      "Epoch: 34 Step: 60 |train loss: 0.00022563934908248484 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 35 Step: 0 |train loss: 0.032948922365903854 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 35 Step: 20 |train loss: 0.0014761185739189386 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 35 Step: 40 |train loss: 0.02319430746138096 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 35 Step: 60 |train loss: 0.0013884353684261441 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 36 Step: 0 |train loss: 0.021456044167280197 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 36 Step: 20 |train loss: 0.0003403186856303364 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 36 Step: 40 |train loss: 0.0026102112606167793 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 36 Step: 60 |train loss: 0.02072061598300934 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 37 Step: 0 |train loss: 0.00041180133121088147 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 37 Step: 20 |train loss: 0.00213670264929533 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 37 Step: 40 |train loss: 0.0009288024739362299 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 37 Step: 60 |train loss: 0.00035678385756909847 |valid accuracy: 0.989041095890411\n",
      "Epoch: 38 Step: 0 |train loss: 0.029169050976634026 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 38 Step: 20 |train loss: 0.0010170078603550792 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 38 Step: 40 |train loss: 0.015748992562294006 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 38 Step: 60 |train loss: 0.0018231439171358943 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 39 Step: 0 |train loss: 0.000281887041637674 |valid accuracy: 0.989041095890411\n",
      "Epoch: 39 Step: 20 |train loss: 0.0009305286221206188 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 39 Step: 40 |train loss: 0.0007527160923928022 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 39 Step: 60 |train loss: 0.0005069065373390913 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 40 Step: 0 |train loss: 0.0009404897573404014 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 40 Step: 20 |train loss: 0.00029198170523159206 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 40 Step: 40 |train loss: 0.0009569310932420194 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 40 Step: 60 |train loss: 0.0004507947014644742 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 41 Step: 0 |train loss: 0.00024696349282748997 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 41 Step: 20 |train loss: 0.00018775940407067537 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 41 Step: 40 |train loss: 0.024381814524531364 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 41 Step: 60 |train loss: 0.00025391101371496916 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 42 Step: 0 |train loss: 0.0002932691713795066 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 42 Step: 20 |train loss: 0.00021610260591842234 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 42 Step: 40 |train loss: 0.002792258281260729 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 42 Step: 60 |train loss: 0.0002716922899708152 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 43 Step: 0 |train loss: 0.00025972365983761847 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 43 Step: 20 |train loss: 0.0004326581838540733 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 43 Step: 40 |train loss: 0.001818244461901486 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 43 Step: 60 |train loss: 0.0019041490741074085 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 44 Step: 0 |train loss: 0.008112127892673016 |valid accuracy: 0.989041095890411\n",
      "Epoch: 44 Step: 20 |train loss: 0.0003727340663317591 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 44 Step: 40 |train loss: 0.004937560763210058 |valid accuracy: 0.9835616438356164\n",
      "Epoch: 44 Step: 60 |train loss: 0.011948227882385254 |valid accuracy: 0.989041095890411\n",
      "Epoch: 45 Step: 0 |train loss: 0.0029592704959213734 |valid accuracy: 0.989041095890411\n",
      "Epoch: 45 Step: 20 |train loss: 0.0006056499551050365 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 45 Step: 40 |train loss: 0.00045040130498819053 |valid accuracy: 0.9863013698630136\n",
      "Epoch: 45 Step: 60 |train loss: 0.002349095419049263 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 46 Step: 0 |train loss: 0.0010312652448192239 |valid accuracy: 0.9863013698630136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 Step: 20 |train loss: 0.0020725964568555355 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 46 Step: 40 |train loss: 0.0002481269766576588 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 46 Step: 60 |train loss: 0.0004487276019062847 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 47 Step: 0 |train loss: 0.0005193996476009488 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 47 Step: 20 |train loss: 0.0032065415289252996 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 47 Step: 40 |train loss: 0.0002647113869898021 |valid accuracy: 0.989041095890411\n",
      "Epoch: 47 Step: 60 |train loss: 0.0003568553947843611 |valid accuracy: 0.9904109589041096\n",
      "Epoch: 48 Step: 0 |train loss: 0.00011231422104174271 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 48 Step: 20 |train loss: 0.00021629333787132055 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 48 Step: 40 |train loss: 0.00015152453852351755 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 48 Step: 60 |train loss: 0.00022480488405562937 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 49 Step: 0 |train loss: 0.00014149189519230276 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 49 Step: 20 |train loss: 0.00016059399058576673 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 49 Step: 40 |train loss: 0.0001573991758050397 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 49 Step: 60 |train loss: 0.00010252952779410407 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 50 Step: 0 |train loss: 0.0007651996565982699 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 50 Step: 20 |train loss: 0.00011901855759788305 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 50 Step: 40 |train loss: 6.883621244924143e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 50 Step: 60 |train loss: 0.0006624936941079795 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 51 Step: 0 |train loss: 0.00014630318037234247 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 51 Step: 20 |train loss: 0.0002038907987298444 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 51 Step: 40 |train loss: 5.557537224376574e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 51 Step: 60 |train loss: 0.0001443529181415215 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 52 Step: 0 |train loss: 0.0001460409112041816 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 52 Step: 20 |train loss: 7.915973401395604e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 52 Step: 40 |train loss: 0.00010513305460335687 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 52 Step: 60 |train loss: 0.0005240726750344038 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 53 Step: 0 |train loss: 9.080886957235634e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 53 Step: 20 |train loss: 0.0002947998000308871 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 53 Step: 40 |train loss: 6.79540607961826e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 53 Step: 60 |train loss: 7.028579420875758e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 54 Step: 0 |train loss: 7.282733713509515e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 54 Step: 20 |train loss: 0.00014349937555380166 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 54 Step: 40 |train loss: 0.003030192805454135 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 54 Step: 60 |train loss: 7.944583921926096e-05 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 55 Step: 0 |train loss: 9.143352508544922e-05 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 55 Step: 20 |train loss: 8.886813884600997e-05 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 55 Step: 40 |train loss: 0.0943695530295372 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 55 Step: 60 |train loss: 0.00013565539848059416 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 56 Step: 0 |train loss: 0.0008772802539169788 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 56 Step: 20 |train loss: 8.239268936449662e-05 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 56 Step: 40 |train loss: 0.00012847900507040322 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 56 Step: 60 |train loss: 0.00031829357612878084 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 57 Step: 0 |train loss: 0.00032459257636219263 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 57 Step: 20 |train loss: 0.0001220893900608644 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 57 Step: 40 |train loss: 0.0003429269709158689 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 57 Step: 60 |train loss: 0.012619581073522568 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 58 Step: 0 |train loss: 0.0013017940800637007 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 58 Step: 20 |train loss: 0.00253328331746161 |valid accuracy: 0.9849315068493151\n",
      "Epoch: 58 Step: 40 |train loss: 0.0015666914405301213 |valid accuracy: 0.989041095890411\n",
      "Epoch: 58 Step: 60 |train loss: 0.017246440052986145 |valid accuracy: 0.989041095890411\n",
      "Epoch: 59 Step: 0 |train loss: 0.03384827449917793 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 59 Step: 20 |train loss: 0.030360041186213493 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 59 Step: 40 |train loss: 0.05513783544301987 |valid accuracy: 0.989041095890411\n",
      "Epoch: 59 Step: 60 |train loss: 0.0024607349187135696 |valid accuracy: 0.9821917808219178\n",
      "Epoch: 60 Step: 0 |train loss: 0.00040451527456752956 |valid accuracy: 0.9876712328767123\n",
      "Epoch: 60 Step: 20 |train loss: 0.002115326002240181 |valid accuracy: 0.989041095890411\n",
      "Epoch: 60 Step: 40 |train loss: 0.06948234885931015 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 60 Step: 60 |train loss: 0.03607497364282608 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 61 Step: 0 |train loss: 0.00020301819313317537 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 61 Step: 20 |train loss: 0.00033515453105792403 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 61 Step: 40 |train loss: 0.0007382202311418951 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 61 Step: 60 |train loss: 0.00012047290510963649 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 62 Step: 0 |train loss: 0.0005440187524072826 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 62 Step: 20 |train loss: 0.0005538940313272178 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 62 Step: 40 |train loss: 0.0017636108677834272 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 62 Step: 60 |train loss: 0.00041543005499988794 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 63 Step: 0 |train loss: 0.00016897200839594007 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 63 Step: 20 |train loss: 8.254528074758127e-05 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 63 Step: 40 |train loss: 0.00014956474478822201 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 63 Step: 60 |train loss: 0.00030753135797567666 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 64 Step: 0 |train loss: 0.0002470636391080916 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 64 Step: 20 |train loss: 0.0005789518472738564 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 64 Step: 40 |train loss: 0.00031082628993317485 |valid accuracy: 0.9917808219178083\n",
      "Epoch: 64 Step: 60 |train loss: 0.0001091194135369733 |valid accuracy: 0.9931506849315068\n",
      "Epoch: 65 Step: 0 |train loss: 0.008226518519222736 |valid accuracy: 0.9945205479452055\n",
      "Epoch: 65 Step: 20 |train loss: 0.0001461648935219273 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 65 Step: 40 |train loss: 0.0024487830232828856 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 65 Step: 60 |train loss: 0.00038576603401452303 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 66 Step: 0 |train loss: 0.00012845992750953883 |valid accuracy: 0.9986301369863013\n",
      "Epoch: 66 Step: 20 |train loss: 0.00043673039181157947 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 66 Step: 40 |train loss: 0.0003204679524060339 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 66 Step: 60 |train loss: 0.000359764089807868 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 67 Step: 0 |train loss: 0.0001260757417185232 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 67 Step: 20 |train loss: 0.00015385627921205014 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 67 Step: 40 |train loss: 0.0001277017581742257 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 67 Step: 60 |train loss: 0.0014902114635333419 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 68 Step: 0 |train loss: 0.0007647800375707448 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 68 Step: 20 |train loss: 6.438255513785407e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 68 Step: 40 |train loss: 3.4394262911519036e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 68 Step: 60 |train loss: 0.0003718423831742257 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 69 Step: 0 |train loss: 6.609439878957346e-05 |valid accuracy: 0.9972602739726028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 Step: 20 |train loss: 6.612777360714972e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 69 Step: 40 |train loss: 9.092330583371222e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 69 Step: 60 |train loss: 5.0578117225086316e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 70 Step: 0 |train loss: 0.00017564772861078382 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 70 Step: 20 |train loss: 6.864070746814832e-05 |valid accuracy: 0.9972602739726028\n",
      "Epoch: 70 Step: 40 |train loss: 2.7503967430675402e-05 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 70 Step: 60 |train loss: 0.00017629146168474108 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 71 Step: 0 |train loss: 5.402088208938949e-05 |valid accuracy: 0.9958904109589041\n",
      "Epoch: 71 Step: 20 |train loss: 0.00010256767563987523 |valid accuracy: 0.9958904109589041\n",
      "End optimization, as there is no inprovement for a long time!\n"
     ]
    }
   ],
   "source": [
    "best_validation_accuracy = 0.0\n",
    "last_improvement = 0\n",
    "require_improvement =3000\n",
    "total_iterations = 0\n",
    "break_signal=0\n",
    "b_x=torch.zeros((BATCH_SIZE,1,16,16))\n",
    "accs=[]\n",
    "\n",
    "#training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    train_loader = Data.DataLoader(dataset=dataset,batch_size=BATCH_SIZE, shuffle=True,drop_last=True)\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        for i in range(BATCH_SIZE):\n",
    "            b_x[i] = transform(x[i])\n",
    "        b_x=Variable(x).cuda()     #GPU\n",
    "        b_y=Variable(y).cuda()     #GPU\n",
    "        total_iterations+=1\n",
    "        output=resnet(b_x)\n",
    "        loss=loss_func(output,b_y)\n",
    "        optimizer.zero_grad()   #clear gradients for this training step\n",
    "        loss.backward()         #backpropagation,compute gradients\n",
    "        optimizer.step()        #apply gradients\n",
    "        if step%20==0:\n",
    "            valid_output =resnet(valid_x).cuda()\n",
    "            pred_y = torch.max(valid_output, 1)[1].cuda().data.squeeze()\n",
    "            accuracy=sum(pred_y==valid_y)/valid_num\n",
    "            accs.append(accuracy)\n",
    "\n",
    "            if accuracy > best_validation_accuracy:  # capture the model of highest presicion\n",
    "                best_validation_accuracy = accuracy\n",
    "                last_improvement = total_iterations\n",
    "                torch.save(resnet, path+Modelname)\n",
    "        if total_iterations - last_improvement > require_improvement:\n",
    "            print(\"End training, as there is no inprovement for a long time!\")\n",
    "            break_signal=1\n",
    "            break\n",
    "    if break_signal: break\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        LR /=2\n",
    "        optimizer = torch.optim.Adam(resnet.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.9986301369863013\n"
     ]
    }
   ],
   "source": [
    "#check the performace of ResNet\n",
    "resnet=torch.load(path+Modelname)\n",
    "valid_output =resnet(valid_x).cuda()\n",
    "pred_y = torch.max(valid_output, 1)[1].cuda().data.squeeze()\n",
    "accuracy=sum(pred_y==valid_y)/valid_num\n",
    "print('Valid accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d44eff0c88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accs,'b-',label='Valid-accuracy')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976581963129\n"
     ]
    }
   ],
   "source": [
    "# Calculate test accuracy\n",
    "test_x=ziptest[:,1:].reshape(-1,16,16)\n",
    "test_x=torch.from_numpy(test_x).type(torch.FloatTensor)     #transform to tensor from\n",
    "test_x=Variable(torch.unsqueeze(test_x,dim=1),volatile=True).cuda()\n",
    "test_y=ziptest[:,0]\n",
    "\n",
    "valid_output = resnet(test_x)\n",
    "pred_y = torch.max(valid_output, 1)[1].cuda().data.squeeze()\n",
    "pred_y=pred_y.cpu()\n",
    "pred_y=pred_y.numpy()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(test_y,pred_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### The highest accuracy achieved by Residual Neural Network in test dataset is 0.97658, which is higher than that of KNN,SVM, Random Forest and MLPC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
